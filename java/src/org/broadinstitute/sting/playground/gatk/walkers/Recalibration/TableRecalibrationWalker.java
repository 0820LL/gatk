package org.broadinstitute.sting.playground.gatk.walkers.Recalibration;

import net.sf.samtools.SAMRecord;
import net.sf.samtools.SAMFileWriter;
import org.broadinstitute.sting.gatk.walkers.ReadWalker;
import org.broadinstitute.sting.gatk.walkers.WalkerName;
import org.broadinstitute.sting.utils.cmdLine.Argument;
import org.broadinstitute.sting.utils.*;

import java.util.ArrayList;
import java.util.List;
import java.util.regex.Pattern;
import java.io.File;
import java.io.FileNotFoundException;

/*
 * Copyright (c) 2009 The Broad Institute
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use,
 * copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the
 * Software is furnished to do so, subject to the following
 * conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
 * OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
 * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
 * WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
 * OTHER DEALINGS IN THE SOFTWARE.
 */

/**
 * Created by IntelliJ IDEA.
 * User: rpoplin
 * Date: Nov 3, 2009
 *
 * This walker is designed to work as the second pass in a two-pass processing step, doing a by-read traversal.

 * For each base in each read this walker calculates various user-specified covariates (such as read group, reported quality score, cycle, and dinuc)
 * Using these values as a key in a large hashmap the walker calculates an empirical base quality score and overwrites the quality score currently in the read.
 * This walker then outputs a new bam file with these updated (recalibrated) reads.
 * 
 * Note: This walker expects as input the recalibration table file generated previously by CovariateCounterWalker.
 * Note: This walker is designed to be used in conjunction with CovariateCounterWalker.
 */

@WalkerName("TableRecalibrationRefactored")
public class TableRecalibrationWalker extends ReadWalker<SAMRecord, SAMFileWriter> {

    @Argument(fullName="recal_file", shortName="recalFile", doc="Input recalibration table file generated by CountCovariates", required=true)
    public String RECAL_FILE;
    @Argument(fullName="outputBam", shortName="outputBam", doc="output BAM file", required=false)
    public SAMFileWriter OUTPUT_BAM = null;
    @Argument(fullName="preserve_qscores_less_than", shortName="pQ", doc="If provided, bases with quality scores less than this threshold won't be recalibrated.  In general its unsafe to change qualities scores below < 5, since base callers use these values to indicate random or bad bases", required=false)
    public int PRESERVE_QSCORES_LESS_THAN = 5;
    @Argument(fullName = "use_original_quals", shortName="OQ", doc="If provided, we will use use the quals from the original qualities OQ attribute field instead of the quals in the regular QUALS field", required=false)
    private boolean USE_ORIGINAL_QUALS = false;
    @Argument(fullName = "platform", shortName="pl", doc="Which sequencing technology was used? This is important for the cycle covariate. Options are SLX, 454, and SOLID.", required=false)
    private String PLATFORM = "SLX";
    @Argument(fullName = "windowSizeNQS", shortName="nqs", doc="How big of a window should the MinimumNQSCovariate use for its calculation", required=false)
    private int WINDOW_SIZE = 3;
    @Argument(fullName="smoothing", shortName="sm", required = false, doc="Number of imaginary counts to add to each bin in order to smooth out bins with few data points")
    public int SMOOTHING = 1;

    //public enum RecalibrationMode {
    //    COMBINATORIAL,
    //    SEQUENTIAL,
    //    ERROR
    //}

    @Argument(fullName="recalibrationMode", shortName="mode", doc="Which calculation to use when recalibrating, default is SEQUENTIAL", required=false)
    public String MODE_STRING = "SEQUENTIAL";
    //public RecalibrationMode MODE = RecalibrationMode.SEQUENTIAL; //BUGBUG: do we need to support the other modes?

    protected RecalDataManager dataManager;
    protected ArrayList<Covariate> requestedCovariates;

    private static Pattern COMMENT_PATTERN = Pattern.compile("^#.*");
    private static Pattern COVARIATE_PATTERN = Pattern.compile("^@!.*");
    
    //---------------------------------------------------------------------------------------------------------------
    //
    // initialize
    //
    //---------------------------------------------------------------------------------------------------------------

    /**
     * Read in the recalibration table input file.
     * Parse the list of covariate classes used during CovariateCounterWalker.
     * Parse the CSV data and populate the hashmap.
     */
    public void initialize() {

        // Get a list of all available covariates
        List<Class<? extends Covariate>> classes = PackageUtils.getClassesImplementingInterface(Covariate.class);

        int lineNumber = 0;
        boolean foundAllCovariates = false;
        //int estimatedCapacity = 1;

        // Read in the covariates that were used from the input file
        requestedCovariates = new ArrayList<Covariate>();


        // Read in the data from the csv file and populate the map
        logger.info( "Reading in the data from input file..." );

        try {
            for ( String line : new xReadLines(new File( RECAL_FILE )) ) {
                lineNumber++;
                if( COMMENT_PATTERN.matcher(line).matches() ) {
                    ; // skip over the comment lines, (which start with '#')
                }
                else if( COVARIATE_PATTERN.matcher(line).matches() ) { // the line string is either specifying a covariate or is giving csv data
                    if( foundAllCovariates ) {
                        throw new StingException( "Malformed input recalibration file. Found covariate names intermingled with data. " + RECAL_FILE );
                    } else { // found another covariate in input file
                        boolean foundClass = false;
                        for( Class<?> covClass : classes ) {

                            if( line.equalsIgnoreCase( "@!" + covClass.getSimpleName() ) ) { // the "@!" was added by CovariateCounterWalker as a code to recognize covariate class names
                                foundClass = true;
                                try {
                                    Covariate covariate = (Covariate)covClass.newInstance();
                                    // some covariates need parameters (user supplied command line arguments) passed to them
                                    if( covariate instanceof CycleCovariate ) { covariate = new CycleCovariate( PLATFORM ); }
                                    else if( covariate instanceof PrimerRoundCovariate ) { covariate = new PrimerRoundCovariate( PLATFORM ); }
                                    else if( covariate instanceof MinimumNQSCovariate ) { covariate = new MinimumNQSCovariate( WINDOW_SIZE ); }
                                    requestedCovariates.add( covariate );
                                    //estimatedCapacity *= covariate.estimatedNumberOfBins();
                                    
                                } catch ( InstantiationException e ) {
                                    throw new StingException( String.format("Can not instantiate covariate class '%s': must be concrete class.", covClass.getSimpleName()) );
                                } catch ( IllegalAccessException e ) {
                                    throw new StingException( String.format("Can not instantiate covariate class '%s': must have no-arg constructor.", covClass.getSimpleName()) );
                                }
                            }
                        }

                        if( !foundClass ) {
                            throw new StingException( "Malformed input recalibration file. The requested covariate type (" + line + ") isn't a valid covariate option." );
                        }

                    }

                } else { // found some data
                    if( !foundAllCovariates ) {
                        foundAllCovariates = true;
                        logger.info( "The covariates being used here: " );
                        logger.info( requestedCovariates );
                        //dataManager = new RecalDataManager( estimatedCapacity );
                        dataManager = new RecalDataManager();

                    }
                    addCSVData(line); // parse the line and add the data to the HashMap
                }
            }

        } catch ( FileNotFoundException e ) {
            Utils.scareUser("Can not find input file: " + RECAL_FILE);
        } catch ( NumberFormatException e ) {
            throw new StingException("Error parsing recalibration data at line " + lineNumber + ". Was your table generated by CountCovariatesRefactored?");
        }
        logger.info( "...done!" );

        // Create the collapsed tables that are used in the sequential calculation
        if( MODE_STRING.equalsIgnoreCase("SEQUENTIAL") ) {
        	logger.info( "Creating collapsed tables for use in sequential calculation..." );
            dataManager.createCollapsedTables( requestedCovariates.size() );
            logger.info( "...done!" );
        }
    }

    /**
     * For each covariate read in a value and parse it. Associate those values with the data itself (num observation and num mismatches)
     * @param line A line of CSV data read from the recalibration table data file
     */
    private void addCSVData(String line) {
        String[] vals = line.split(",");
        ArrayList<Comparable> key = new ArrayList<Comparable>();
        Covariate cov;
        int iii;
        for( iii = 0; iii < requestedCovariates.size(); iii++ ) {
            cov = requestedCovariates.get( iii );
            key.add( cov.getValue( vals[iii] ) );
        }
        RecalDatum datum = new RecalDatum( Long.parseLong( vals[iii] ), Long.parseLong( vals[iii + 1] ) );
        dataManager.data.put( key, datum );
    }

    //---------------------------------------------------------------------------------------------------------------
    //
    // map
    //
    //---------------------------------------------------------------------------------------------------------------

    /**
     * For each base in the read calculate a new recalibrated quality score and replace the quality scores in the read
     * @param refBases References bases over the length of the read
     * @param read The read to be recalibrated
     * @return The read with quality scores replaced
     */
    public SAMRecord map( char[] refBases, SAMRecord read ) {

        if( refBases == null ) {
            return read; // early return here, unmapped reads should be left alone
        }

        byte[] originalQuals = read.getBaseQualities();
        // Check if we need to use the original quality scores instead
        if ( USE_ORIGINAL_QUALS && read.getAttribute(RecalDataManager.ORIGINAL_QUAL_ATTRIBUTE_TAG) != null ) {
            Object obj = read.getAttribute(RecalDataManager.ORIGINAL_QUAL_ATTRIBUTE_TAG);
            if ( obj instanceof String )
                originalQuals = QualityUtils.fastqToPhred((String)obj);
            else {
                throw new RuntimeException(String.format("Value encoded by %s in %s isn't a string!", RecalDataManager.ORIGINAL_QUAL_ATTRIBUTE_TAG, read.getReadName()));
            }
        }
        byte[] recalQuals = originalQuals.clone();

        // These calls are expensive so only do them once for each read
        String readGroup = read.getReadGroup().getReadGroupId();
        char[] bases = read.getReadString().toCharArray();
        if( refBases.length != bases.length ) {
            return read; // something is wrong with the mapping of the read so leave it alone
        }
        String myRefBases = new String(refBases);
        if( read.getReadNegativeStrandFlag() ) {
            bases = BaseUtils.simpleComplement( read.getReadString() ).toCharArray();
            myRefBases = BaseUtils.simpleComplement( myRefBases );
        }


        // For each base in the read
        for( int iii = 1; iii < read.getReadLength() - 1; iii++ ) { // skip first and last bases because there is no dinuc
            List<Comparable> key = new ArrayList<Comparable>();
            for( Covariate covariate : requestedCovariates ) {
                key.add( covariate.getValue( read, iii, readGroup, originalQuals, bases, myRefBases.charAt(iii) ) ); // offset is zero based so passing iii is correct here                      // technically COVARIATE_ERROR is fine too, but this won't match the behavior of the old recalibrator
            }

            if( MODE_STRING.equalsIgnoreCase("COMBINATORIAL") ) {
                RecalDatum datum = dataManager.data.get( key );
                if( datum != null ) { // if we have data for this combination of covariates then recalibrate the quality score otherwise do nothing
                    recalQuals[iii] = datum.empiricalQualByte( SMOOTHING );
                }
            } else if( MODE_STRING.equalsIgnoreCase("SEQUENTIAL") ) {
                recalQuals[iii] = performSequentialQualityCalculation( key );
            } else {
                throw new StingException( "Specified RecalibrationMode is not supported: " + MODE_STRING );
            }

            // Do some error checking on the new quality score
            if ( recalQuals[iii]  <= 0 || recalQuals[iii]  > QualityUtils.MAX_REASONABLE_Q_SCORE ) {
                throw new StingException( "Assigning bad quality score " + key + " => " +  recalQuals[iii] );
            }
        }

        preserveQScores( originalQuals, recalQuals ); // overwrite the work done if original quality score is too low
        read.setBaseQualities(recalQuals); // overwrite old qualities with new recalibrated qualities
        if ( read.getAttribute(RecalDataManager.ORIGINAL_QUAL_ATTRIBUTE_TAG) == null ) { // save the old qualities if the tag isn't already taken in the read
            read.setAttribute(RecalDataManager.ORIGINAL_QUAL_ATTRIBUTE_TAG, QualityUtils.phredToFastq(originalQuals));
        }


        return read;
    }

    /**
     * Implements a serial recalibration of the reads using the combinational table.  First,
     * we perform a positional recalibration, and then a subsequent dinuc correction.
     *
     * Given the full recalibration table, we perform the following preprocessing steps:
     *
     *   - calculate the global quality score shift across all data [DeltaQ]
     *   - calculate for each of cycle and dinuc the shift of the quality scores relative to the global shift
     *      -- i.e., DeltaQ(dinuc) = Sum(pos) Sum(Qual) Qempirical(pos, qual, dinuc) - Qreported(pos, qual, dinuc) / Npos * Nqual
     *   - The final shift equation is:
     *
     *      Qrecal = Qreported + DeltaQ + DeltaQ(pos) + DeltaQ(dinuc) + DeltaQ( ... any other covariate ... ) 
     * @param key The list of Comparables that were calculated from the covariates
     * @return A recalibrated quality score as a byte
     */
    private byte performSequentialQualityCalculation( List<? extends Comparable> key ) {

        byte qualFromRead = Byte.parseByte(key.get(1).toString());
        ArrayList<Comparable> newKey;
        
        newKey = new ArrayList<Comparable>();
        newKey.add( key.get(0) ); // read group
        RecalDatum globalDeltaQDatum = dataManager.getCollapsedTable(0).get( newKey );
        double globalDeltaQ = 0.0;
        double aggregrateQreported = 0.0;
        if( globalDeltaQDatum != null ) {
        	aggregrateQreported = QualityUtils.phredScaleErrorRate( dataManager.dataSumExpectedErrors.get( newKey ) / ((double) globalDeltaQDatum.getNumObservations()) );
           globalDeltaQ = globalDeltaQDatum.empiricalQualDouble( SMOOTHING ) - aggregrateQreported;
        }
        
       
        newKey = new ArrayList<Comparable>();
        newKey.add( key.get(0) ); // read group
        newKey.add( key.get(1) ); // quality score
        RecalDatum deltaQReportedDatum = dataManager.getCollapsedTable(1).get( newKey );
        double deltaQReported = 0.0;
        if( deltaQReportedDatum != null ) {
            deltaQReported = deltaQReportedDatum.empiricalQualDouble( SMOOTHING ) - qualFromRead - globalDeltaQ;
        }
        
        
        double deltaQCovariates = 0.0;
        RecalDatum deltaQCovariateDatum;
        for( int iii = 2; iii < key.size(); iii++ ) {
            newKey = new ArrayList<Comparable>();
            newKey.add( key.get(0) ); // read group
            newKey.add( key.get(1) ); // quality score
            newKey.add( key.get(iii) ); // given covariate
            deltaQCovariateDatum = dataManager.getCollapsedTable(iii).get( newKey );
            if( deltaQCovariateDatum != null ) {
                deltaQCovariates += ( deltaQCovariateDatum.empiricalQualDouble( SMOOTHING ) - qualFromRead - (globalDeltaQ + deltaQReported) );
            }
        }

        double newQuality = qualFromRead + globalDeltaQ + deltaQReported + deltaQCovariates;
        byte newQualityByte = QualityUtils.boundQual( (int)Math.round(newQuality), QualityUtils.MAX_REASONABLE_Q_SCORE );


        // Verbose printouts used to validate with old recalibrator
        //if(key.contains(null)) {
        //    System.out.println( key  + String.format(" => %d + %.2f + %.2f + %.2f + %.2f = %d",
        //                 qualFromRead, globalDeltaQ, deltaQReported, deltaQPos, deltaQDinuc, newQualityByte));
        //}
        //else {
        //    System.out.println( String.format("%s %s %s %s => %d + %.2f + %.2f + %.2f + %.2f = %d",
        //                 key.get(0).toString(), key.get(3).toString(), key.get(2).toString(), key.get(1).toString(), qualFromRead, globalDeltaQ, deltaQReported, deltaQPos, deltaQDinuc, newQualityByte) );
        //}

        if( newQualityByte <= 0 && newQualityByte >= QualityUtils.MAX_REASONABLE_Q_SCORE ) {
            throw new StingException( "Illegal base quality score calculated: " + key +
                        String.format( " => %d + %.2f + %.2f + %.2f = %d", qualFromRead, globalDeltaQ, deltaQReported, deltaQCovariates, newQualityByte ) );
        }
        
        return newQualityByte;
    }

    /**
     * Loop of the list of qualities and overwrite the newly recalibrated score to be the original score if it was less than some threshold
     * @param originalQuals The list of original base quality scores
     * @param recalQuals A list of the new recalibrated quality scores
     */
    private void preserveQScores( byte[] originalQuals, byte[] recalQuals ) {
        for( int iii = 0; iii < recalQuals.length; iii++ ) {
            if ( originalQuals[iii] < PRESERVE_QSCORES_LESS_THAN ) {
                recalQuals[iii] = originalQuals[iii];
            }
        }
    }

    //---------------------------------------------------------------------------------------------------------------
    //
    // reduce
    //
    //---------------------------------------------------------------------------------------------------------------

    /**
     * Nothing start the reduce with a new handle to the output bam file
     * @return A FileWriter pointing to a new bam file
     */
    public SAMFileWriter reduceInit() {
        return OUTPUT_BAM;
    }

    /**
     * Output each read to disk
     * @param read The read to output
     * @param output The FileWriter to write the read to
     * @return The FileWriter
     */
    public SAMFileWriter reduce( SAMRecord read, SAMFileWriter output ) {
        if ( output != null ) {
            output.addAlignment(read);
        } else {
            out.println(read.format());
        }

        return output;
    }
}
